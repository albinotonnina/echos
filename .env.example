# Required
TELEGRAM_BOT_TOKEN=
ALLOWED_USER_IDS=

# LLM provider â€” set at least one of the two options below.
# Option A: Anthropic (pay-as-you-go API plan required, NOT a Claude subscription)
# Get your API key at: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=

# Option B: Any other provider supported by pi-ai (Groq, Mistral, xAI, etc.)
# Set DEFAULT_MODEL to a matching model spec, e.g. groq/llama-3.3-70b-versatile
LLM_API_KEY=

# Option B (custom endpoint): OpenAI-compatible API (DeepInfra, local Ollama, etc.)
# Requires LLM_API_KEY. Set DEFAULT_MODEL to the model ID expected by the endpoint.
# Example: LLM_BASE_URL=https://api.deepinfra.com/v1/openai
#          DEFAULT_MODEL=meta-llama/Meta-Llama-3.1-70B-Instruct
LLM_BASE_URL=

# Optional (needed for embeddings, Whisper)
OPENAI_API_KEY=

# Redis
REDIS_URL=redis://localhost:6379

# Storage paths
KNOWLEDGE_DIR=./data/knowledge
DB_PATH=./data/db
SESSION_DIR=./data/sessions

# LLM settings
DEFAULT_MODEL=claude-haiku-4-5-20251001
EMBEDDING_MODEL=text-embedding-3-small
# Vector dimensions (must match model output). text-embedding-3-* models support truncation.
# To use text-embedding-3-large with 1536 dims: set EMBEDDING_MODEL=text-embedding-3-large
# To change dimensions: delete data/db/vectors/ and run pnpm reconcile
EMBEDDING_DIMENSIONS=1536

# Interfaces (enable/disable) - See docs/INTERFACES.md for details
# Telegram: Message-based bot interface (requires bot token)
ENABLE_TELEGRAM=true
# Web: HTTP API server for integrations
ENABLE_WEB=true

# Web UI
# Port for Web API server (if ENABLE_WEB=true)
WEB_PORT=3000

# Scheduler (requires Redis running on REDIS_URL)
# Set to true to enable background job processing (digests, reminders)
# If Redis is unavailable at startup, the scheduler is skipped gracefully.
ENABLE_SCHEDULER=false

# Webshare Proxy (optional, for YouTube rate-limit bypass)
# WEBSHARE_PROXY_USERNAME=
# WEBSHARE_PROXY_PASSWORD=


WEB_API_KEY=your-secure-web-api-key-here